# ğŸ§  Projeto de ExtraÃ§Ã£o e AutomaÃ§Ã£o de Dados - Lenarge Scraping Table

## ğŸ“‹ DescriÃ§Ã£o Geral

Este projeto tem como objetivo automatizar **a extraÃ§Ã£o, manipulaÃ§Ã£o,
tratamento e armazenamento de dados** provenientes da aplicaÃ§Ã£o
**Lenarge**, utilizando **Selenium para web scraping**, manipulaÃ§Ã£o de
arquivos locais e integraÃ§Ã£o com **MySQL** para persistÃªncia de dados.

A estrutura foi desenvolvida para permitir **reutilizaÃ§Ã£o modular**, de
forma que os dados extraÃ­dos possam ser utilizados em **relatÃ³rios
automÃ¡ticos**, **subextraÃ§Ãµes especÃ­ficas** e **integraÃ§Ãµes com outros
sistemas administrativos**.

------------------------------------------------------------------------

## ğŸš€ Funcionalidades Principais

### 1. ExtraÃ§Ã£o de Dados (Web Scraping)

-   ExtraÃ§Ã£o de tabelas do app Lenarge utilizando **Selenium
    WebDriver**.
-   LocalizaÃ§Ã£o dinÃ¢mica de elementos com **XPath otimizados**.
-   Scroll automatizado e iteraÃ§Ã£o em carrossÃ©is e tabelas dinÃ¢micas.
-   Armazenamento temporÃ¡rio em arquivos `.xlsx` ou `.csv` gerados
    automaticamente.

### 2. ManipulaÃ§Ã£o de Pastas e Arquivos

-   FunÃ§Ã£o `manipulacao_path()` com lÃ³gica iterativa e validada.
-   VerificaÃ§Ã£o das variÃ¡veis de ambiente (`PATH_DOWNLOAD`, `PATH_DATA`)
    com tratamento de erro profissional.
-   IdentificaÃ§Ã£o automÃ¡tica do arquivo mais recente baseado no padrÃ£o
    de nomeaÃ§Ã£o.
-   MovimentaÃ§Ã£o segura do arquivo mais recente para o diretÃ³rio de
    destino.
-   GeraÃ§Ã£o de nomes padronizados e limpos com `safe_filename()`.

### 3. Tratamento e PadronizaÃ§Ã£o dos Dados

-   NormalizaÃ§Ã£o de colunas com nomes consistentes e legÃ­veis.
-   ConversÃ£o de tipos (string â†’ int, float, datetime) para
    compatibilidade SQL.
-   RemoÃ§Ã£o de duplicatas e registros inconsistentes.
-   Enriquecimento com colunas derivadas (ex: data de extraÃ§Ã£o, fonte,
    identificadores Ãºnicos).
-   TransformaÃ§Ã£o em formato tabular ideal para uso em bancos
    relacionais.

### 4. IntegraÃ§Ã£o com Banco de Dados MySQL

-   ConexÃ£o via `mysql.connector` ou `SQLAlchemy`.
-   CriaÃ§Ã£o automÃ¡tica de tabelas se nÃ£o existirem.
-   InserÃ§Ã£o incremental (append) de novos dados sem sobrescrever
    histÃ³ricos.
-   Logs de execuÃ§Ã£o e falhas de conexÃ£o.
-   Scripts configurÃ¡veis para rodar localmente ou em servidores
    remotos.

### 5. ReutilizaÃ§Ã£o e Modularidade

-   O projeto foi estruturado para permitir uso em **outros scripts e
    automaÃ§Ãµes**, como:
    -   GeraÃ§Ã£o de relatÃ³rios diÃ¡rios ou semanais;
    -   SubextraÃ§Ãµes de dados especÃ­ficas (clientes, transportadoras,
        notas, etc);
    -   Dashboards e integraÃ§Ãµes com Power BI ou Google Data Studio.

------------------------------------------------------------------------

## âš™ï¸ Estrutura Recomendada de Pastas

    ScrapingTable/
    â”‚
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ main.py                # ExecuÃ§Ã£o principal da extraÃ§Ã£o
    â”‚   â”œâ”€â”€ utils/
    â”‚   â”‚   â”œâ”€â”€ scraping.py        # FunÃ§Ãµes Selenium e XPaths
    â”‚   â”‚   â”œâ”€â”€ look_path.py       # ManipulaÃ§Ã£o de diretÃ³rios e arquivos
    â”‚   â”‚   â”œâ”€â”€ data_clean.py      # Tratamento e normalizaÃ§Ã£o dos dados
    â”‚   â”‚   â””â”€â”€ db_mysql.py        # IntegraÃ§Ã£o e inserÃ§Ã£o no MySQL
    â”‚   â”‚
    â”‚   â””â”€â”€ config/
    â”‚       â””â”€â”€ .env               # VariÃ¡veis de ambiente (PATH_DOWNLOAD, PATH_DATA, DB_CREDENTIALS)
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ raw/                   # Dados brutos extraÃ­dos
    â”‚   â””â”€â”€ processed/             # Dados tratados e prontos para carga
    â”‚
    â””â”€â”€ README.md

------------------------------------------------------------------------

## ğŸ› ï¸ Tecnologias Utilizadas

  Categoria                 Ferramenta
  ------------------------- -------------------------------
  Web Scraping              Selenium, XPath, ChromeDriver
  ManipulaÃ§Ã£o de Arquivos   pathlib, shutil
  Tratamento de Dados       pandas, datetime
  Banco de Dados            MySQL, SQLAlchemy
  AutomaÃ§Ã£o                 Python 3.11+
  Ambiente                  `.env`, dotenv

------------------------------------------------------------------------

## ğŸ§© Fluxo de ExecuÃ§Ã£o

1.  **ExtraÃ§Ã£o:** Selenium acessa o app Lenarge, localiza e exporta a
    tabela desejada.\
2.  **ManipulaÃ§Ã£o:** O arquivo mais recente Ã© identificado e movido para
    o diretÃ³rio `data/processed`.\
3.  **Tratamento:** Os dados sÃ£o normalizados, limpos e convertidos para
    um formato padrÃ£o.\
4.  **PersistÃªncia:** InserÃ§Ã£o no banco de dados MySQL com checagem de
    duplicatas.\
5.  **Reuso:** O dataset consolidado Ã© utilizado em relatÃ³rios,
    automaÃ§Ãµes e anÃ¡lises.

------------------------------------------------------------------------

## ğŸ§° ConfiguraÃ§Ã£o do Ambiente

1.  **Instale as dependÃªncias**

    ``` bash
    pip install -r requirements.txt
    ```

2.  **Configure o arquivo `.env`**

    ``` env
    PATH_DOWNLOAD=C:\Users\user\Downloads
    PATH_DATA=C:\Users\user\Documents\data_processed
    MYSQL_USER=root
    MYSQL_PASSWORD=senha
    MYSQL_DB=lenarge_data
    MYSQL_HOST=localhost
    ```

3.  **Execute o script principal**

    ``` bash
    python src/main.py
    ```

------------------------------------------------------------------------

## ğŸ§  Futuras ExpansÃµes

-   AdiÃ§Ã£o de logs detalhados (logging + monitoramento).
-   Agendamento automÃ¡tico com Airflow ou cron jobs.
-   Deploy em nuvem (Google Cloud ou AWS) com execuÃ§Ã£o remota.
-   IntegraÃ§Ã£o com dashboards analÃ­ticos.

------------------------------------------------------------------------

## ğŸ§¾ LicenÃ§a

Este projeto Ã© de uso interno e educativo.\
Desenvolvido com foco em automaÃ§Ã£o e integraÃ§Ã£o de dados
administrativos e profissionais.


