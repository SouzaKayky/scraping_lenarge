# üß† Projeto de Extra√ß√£o e Automa√ß√£o de Dados - Lenarge Scraping Table

> ‚öôÔ∏è **Importante:**  
> O processo de **extra√ß√£o da tabela j√° existe nativamente dentro do aplicativo Lenarge**.  
> O Selenium neste projeto **n√£o realiza a coleta linha a linha**, mas sim **automatiza o login, a navega√ß√£o e o download da tabela de dados** no formato padr√£o disponibilizado pelo sistema.

Este projeto se diferencia do reposit√≥rio **`web_scraping_v2`**, que foi criado posteriormente.  
Enquanto este projeto (v1) automatiza o **download direto** da tabela export√°vel, o **v2 surgiu da necessidade de extrair dados linha a linha via Selenium** ‚Äî pois, em certas situa√ß√µes, **o app n√£o permitia a exporta√ß√£o complexa ou completa**, dificultando o tratamento posterior.

Portanto, este reposit√≥rio pode ser considerado **a vers√£o inicial (v1)** do pipeline de extra√ß√£o, com base s√≥lida e modular, sobre a qual o **v2 foi evolu√≠do** para resolver limita√ß√µes de acessibilidade e granularidade dos dados.

[Reposit√≥rio scraping_lenarge_v2](https://github.com/SouzaKayky/scraping_lenarge_v2)

------------------------------------------------------------------------

## üöÄ Funcionalidades Principais

### 1. Acesso e Download Automatizado (Web Scraping Simplificado)
- O Selenium √© utilizado **somente para login, navega√ß√£o e download autom√°tico** da tabela disponibilizada pelo app Lenarge.  
- O download segue um padr√£o de nome (`programacao--YYYY-MM-DD...`) e √© salvo automaticamente na pasta de downloads.  
- O script identifica o arquivo mais recente e o move para o diret√≥rio de processamento.  
- Este fluxo garante **extra√ß√µes padronizadas e reprodut√≠veis**, sem depender de a√ß√µes manuais.

### 2. Manipula√ß√£o de Pastas e Arquivos
- Fun√ß√£o `manipulacao_path()` com estrutura iterativa e valida√ß√µes robustas.  
- Verifica√ß√£o das vari√°veis de ambiente (`PATH_DOWNLOAD`, `PATH_DATA`).  
- Cria√ß√£o de diret√≥rios ausentes e tratamento de erros padronizado.  
- Movimenta√ß√£o segura do arquivo mais recente, renomeando conforme timestamp.  
- Garantia de que apenas o √∫ltimo arquivo modificado √© considerado v√°lido.

### 3. Tratamento e Padroniza√ß√£o dos Dados
- Detec√ß√£o autom√°tica do delimitador e corre√ß√£o de encoding (`UTF-8`).
- Remo√ß√£o de colunas vazias, duplicadas e dados redundantes.
- Padroniza√ß√£o de strings e normaliza√ß√£o de tipos num√©ricos e categ√≥ricos.
- Convers√£o de dados para tipos otimizados (`float32`, `int32`, `category`).  
- Estrutura final ideal para inser√ß√£o em bancos relacionais (MySQL).

### Resultado Exibido

Linhas totais        : 1952
Tamanho original     : 0.53 MB
Tamanho otimizado    : 0.48 MB
Redu√ß√£o de tamanho   : 10.6%

### 4. Integra√ß√£o com Banco de Dados MySQL
- Conex√£o via `mysql.connector` ou `SQLAlchemy`.  
- Cria√ß√£o autom√°tica de tabelas (DDL din√¢mica).  
- Inser√ß√£o incremental, evitando sobrescrever hist√≥ricos.  
- Logs detalhados de execu√ß√£o e falhas.  
- Compat√≠vel com execu√ß√µes locais e remotas (via script ou automa√ß√£o agendada).

### 5. Reutiliza√ß√£o e Modularidade
Este projeto serve como **base de dados oficial** para:
- Relat√≥rios e dashboards gerenciais;
- Subextra√ß√µes espec√≠ficas (clientes, transportadoras, notas, etc.);
- Integra√ß√µes com pipelines de automa√ß√£o financeira e operacional;
- Scripts complementares que utilizam os dados baixados e tratados.

------------------------------------------------------------------------

## üöö Exemplo Pr√°tico de Aplica√ß√£o
Um exemplo real de uso dos dados extra√≠dos deste projeto ocorre em uma **tabela compartilhada com os programadores de log√≠stica de cargas**, utilizada para o **controle de paradas de caminh√µes para manuten√ß√£o preventiva**.

Nessa tabela, cada linha representa um ve√≠culo e cont√©m:
- **Placa do caminh√£o**;  
- **Respons√°vel atual** (progamador de carga);  
- **Motorista logado** no momento da extra√ß√£o;  
- **Informa√ß√µes adicionais** .

Essa automa√ß√£o garante que a equipe de log√≠stica **tenha uma vis√£o consolidada e atualizada** dos caminh√µes, simplificando o processo de **cobran√ßa e controle de paradas** para manuten√ß√£o preventiva e corretiva.

------------------------------------------------------------------------

## ‚öôÔ∏è Estrutura Recomendada de Pastas

    ScrapingTable/
    ‚îÇ
    ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îú‚îÄ‚îÄ main.py                # Execu√ß√£o principal da extra√ß√£o
    ‚îÇ   ‚îú‚îÄ‚îÄ utils/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraping.py        # Fun√ß√µes Selenium e XPaths
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ look_path.py       # Manipula√ß√£o de diret√≥rios e arquivos
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_clean.py      # Tratamento e normaliza√ß√£o dos dados
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ db_mysql.py        # Integra√ß√£o e inser√ß√£o no MySQL
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ config/
    ‚îÇ       ‚îî‚îÄ‚îÄ .env               # Vari√°veis de ambiente (PATH_DOWNLOAD, PATH_DATA, DB_CREDENTIALS)
    ‚îÇ
    ‚îú‚îÄ‚îÄ data/
    ‚îÇ   ‚îú‚îÄ‚îÄ raw/                   # Dados brutos extra√≠dos
    ‚îÇ   ‚îî‚îÄ‚îÄ processed/             # Dados tratados e prontos para carga
    ‚îÇ
    ‚îî‚îÄ‚îÄ README.md

------------------------------------------------------------------------

## üõ†Ô∏è Tecnologias Utilizadas

  Categoria                 Ferramenta
  ------------------------- -------------------------------
  Web Scraping              Selenium, XPath, ChromeDriver
  Manipula√ß√£o de Arquivos   pathlib, shutil
  Tratamento de Dados       pandas, datetime
  Banco de Dados            MySQL, SQLAlchemy
  Automa√ß√£o                 Python 3.11+
  Ambiente                  `.env`, dotenv

------------------------------------------------------------------------

## üß© Fluxo de Execu√ß√£o

1.  **Extra√ß√£o:** Selenium acessa o app Lenarge, localiza e exporta a
    tabela desejada.\
2.  **Manipula√ß√£o:** O arquivo mais recente √© identificado e movido para
    o diret√≥rio `data/processed`.\
3.  **Tratamento:** Os dados s√£o normalizados, limpos e convertidos para
    um formato padr√£o.\
4.  **Persist√™ncia:** Inser√ß√£o no banco de dados MySQL com checagem de
    duplicatas.\
5.  **Reuso:** O dataset consolidado √© utilizado em relat√≥rios,
    automa√ß√µes e an√°lises.

------------------------------------------------------------------------

## üß∞ Configura√ß√£o do Ambiente

1.  **Instale as depend√™ncias**

    ``` bash
    pip install -r requirements.txt
    ```

2.  **Configure o arquivo `.env`**

    ``` env
    PATH_DOWNLOAD=C:\Users\user\Downloads
    PATH_DATA=C:\Users\user\Documents\data_processed
    MYSQL_USER=root
    MYSQL_PASSWORD=senha
    MYSQL_DB=lenarge_data
    MYSQL_HOST=localhost
    ```

3.  **Execute o script principal**

    ``` bash
    python src/main.py
    ```

------------------------------------------------------------------------

## üß† Futuras Expans√µes

-   Adi√ß√£o de logs detalhados (logging + monitoramento).
-   Agendamento autom√°tico com Airflow ou cron jobs.
-   Deploy em nuvem (Google Cloud ou AWS) com execu√ß√£o remota.
-   Integra√ß√£o com dashboards anal√≠ticos.

------------------------------------------------------------------------

## üßæ Licen√ßa

Este projeto √© de uso interno e educativo.\
Desenvolvido com foco em automa√ß√£o e integra√ß√£o de dados
administrativos e profissionais.


