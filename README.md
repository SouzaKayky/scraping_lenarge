# ğŸ§  Projeto de ExtraÃ§Ã£o e AutomaÃ§Ã£o de Dados - Lenarge Scraping Table

## ğŸ“‹ DescriÃ§Ã£o Geral
Este projeto tem como objetivo **automatizar o processo de extraÃ§Ã£o, manipulaÃ§Ã£o, tratamento e armazenamento de dados** provenientes da aplicaÃ§Ã£o **Lenarge**, utilizando **Selenium** apenas como ferramenta de **acesso e download automÃ¡tico** da tabela disponibilizada diretamente pelo prÃ³prio app.

> âš™ï¸ **Importante:**  
> O processo de **extraÃ§Ã£o da tabela jÃ¡ existe nativamente dentro do aplicativo Lenarge**.  
> O papel do Selenium neste projeto **nÃ£o Ã© extrair linha a linha** da interface, mas sim **automatizar o acesso, navegaÃ§Ã£o e download** da tabela em seu formato padrÃ£o atual, garantindo consistÃªncia e periodicidade.

Este projeto se diferencia do repositÃ³rio **`web_scraping_v2`**, onde o Selenium Ã© usado de forma mais profunda â€” lÃ¡ ele **navega, coleta e reconstrÃ³i dados linha a linha** devido Ã  ausÃªncia de uma funÃ§Ã£o de exportaÃ§Ã£o complexa no aplicativo.  
Aqui, o foco Ã© **otimizar o processo jÃ¡ existente** e integrÃ¡-lo a fluxos automatizados de manipulaÃ§Ã£o e armazenamento.

A estrutura foi desenvolvida para permitir **reutilizaÃ§Ã£o modular**, de forma que os dados extraÃ­dos possam ser utilizados em **relatÃ³rios automÃ¡ticos**, **subextraÃ§Ãµes especÃ­ficas** e **integraÃ§Ãµes com outros sistemas administrativos**.

------------------------------------------------------------------------

## ğŸš€ Funcionalidades Principais

### 1. Acesso e Download Automatizado (Web Scraping Simplificado)
- O Selenium Ã© utilizado **somente para login, navegaÃ§Ã£o e download automÃ¡tico** da tabela disponibilizada pelo app Lenarge.  
- O download segue um padrÃ£o de nome (`programacao--YYYY-MM-DD...`) e Ã© salvo automaticamente na pasta de downloads.  
- O script identifica o arquivo mais recente e o move para o diretÃ³rio de processamento.  
- Este fluxo garante **extraÃ§Ãµes padronizadas e reprodutÃ­veis**, sem depender de aÃ§Ãµes manuais.

### 2. ManipulaÃ§Ã£o de Pastas e Arquivos
- FunÃ§Ã£o `manipulacao_path()` com estrutura iterativa e validaÃ§Ãµes robustas.  
- VerificaÃ§Ã£o das variÃ¡veis de ambiente (`PATH_DOWNLOAD`, `PATH_DATA`).  
- CriaÃ§Ã£o de diretÃ³rios ausentes e tratamento de erros padronizado.  
- MovimentaÃ§Ã£o segura do arquivo mais recente, renomeando conforme timestamp.  
- Garantia de que apenas o Ãºltimo arquivo modificado Ã© considerado vÃ¡lido.

### 3. Tratamento e PadronizaÃ§Ã£o dos Dados
- PadronizaÃ§Ã£o de nomes de colunas e normalizaÃ§Ã£o de formatos.  
- ConversÃµes seguras de tipo (string â†’ numÃ©rico, datetime).  
- EliminaÃ§Ã£o de duplicatas e inconsistÃªncias.  
- Enriquecimento com colunas de metadados (ex: data de extraÃ§Ã£o, fonte, id Ãºnico).  
- Estrutura final ideal para inserÃ§Ã£o em bancos relacionais (MySQL).

### 4. IntegraÃ§Ã£o com Banco de Dados MySQL
- ConexÃ£o via `mysql.connector` ou `SQLAlchemy`.  
- CriaÃ§Ã£o automÃ¡tica de tabelas (DDL dinÃ¢mica).  
- InserÃ§Ã£o incremental, evitando sobrescrever histÃ³ricos.  
- Logs detalhados de execuÃ§Ã£o e falhas.  
- CompatÃ­vel com execuÃ§Ãµes locais e remotas (via script ou automaÃ§Ã£o agendada).

### 5. ReutilizaÃ§Ã£o e Modularidade
Este projeto serve como **base de dados oficial** para:
- RelatÃ³rios e dashboards gerenciais;
- SubextraÃ§Ãµes especÃ­ficas (clientes, transportadoras, notas, etc.);
- IntegraÃ§Ãµes com pipelines de automaÃ§Ã£o financeira e operacional;
- Scripts complementares que utilizam os dados baixados e tratados.

------------------------------------------------------------------------

## âš™ï¸ Estrutura Recomendada de Pastas

    ScrapingTable/
    â”‚
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ main.py                # ExecuÃ§Ã£o principal da extraÃ§Ã£o
    â”‚   â”œâ”€â”€ utils/
    â”‚   â”‚   â”œâ”€â”€ scraping.py        # FunÃ§Ãµes Selenium e XPaths
    â”‚   â”‚   â”œâ”€â”€ look_path.py       # ManipulaÃ§Ã£o de diretÃ³rios e arquivos
    â”‚   â”‚   â”œâ”€â”€ data_clean.py      # Tratamento e normalizaÃ§Ã£o dos dados
    â”‚   â”‚   â””â”€â”€ db_mysql.py        # IntegraÃ§Ã£o e inserÃ§Ã£o no MySQL
    â”‚   â”‚
    â”‚   â””â”€â”€ config/
    â”‚       â””â”€â”€ .env               # VariÃ¡veis de ambiente (PATH_DOWNLOAD, PATH_DATA, DB_CREDENTIALS)
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ raw/                   # Dados brutos extraÃ­dos
    â”‚   â””â”€â”€ processed/             # Dados tratados e prontos para carga
    â”‚
    â””â”€â”€ README.md

------------------------------------------------------------------------

## ğŸ› ï¸ Tecnologias Utilizadas

  Categoria                 Ferramenta
  ------------------------- -------------------------------
  Web Scraping              Selenium, XPath, ChromeDriver
  ManipulaÃ§Ã£o de Arquivos   pathlib, shutil
  Tratamento de Dados       pandas, datetime
  Banco de Dados            MySQL, SQLAlchemy
  AutomaÃ§Ã£o                 Python 3.11+
  Ambiente                  `.env`, dotenv

------------------------------------------------------------------------

## ğŸ§© Fluxo de ExecuÃ§Ã£o

1.  **ExtraÃ§Ã£o:** Selenium acessa o app Lenarge, localiza e exporta a
    tabela desejada.\
2.  **ManipulaÃ§Ã£o:** O arquivo mais recente Ã© identificado e movido para
    o diretÃ³rio `data/processed`.\
3.  **Tratamento:** Os dados sÃ£o normalizados, limpos e convertidos para
    um formato padrÃ£o.\
4.  **PersistÃªncia:** InserÃ§Ã£o no banco de dados MySQL com checagem de
    duplicatas.\
5.  **Reuso:** O dataset consolidado Ã© utilizado em relatÃ³rios,
    automaÃ§Ãµes e anÃ¡lises.

------------------------------------------------------------------------

## ğŸ§° ConfiguraÃ§Ã£o do Ambiente

1.  **Instale as dependÃªncias**

    ``` bash
    pip install -r requirements.txt
    ```

2.  **Configure o arquivo `.env`**

    ``` env
    PATH_DOWNLOAD=C:\Users\user\Downloads
    PATH_DATA=C:\Users\user\Documents\data_processed
    MYSQL_USER=root
    MYSQL_PASSWORD=senha
    MYSQL_DB=lenarge_data
    MYSQL_HOST=localhost
    ```

3.  **Execute o script principal**

    ``` bash
    python src/main.py
    ```

------------------------------------------------------------------------

## ğŸ§  Futuras ExpansÃµes

-   AdiÃ§Ã£o de logs detalhados (logging + monitoramento).
-   Agendamento automÃ¡tico com Airflow ou cron jobs.
-   Deploy em nuvem (Google Cloud ou AWS) com execuÃ§Ã£o remota.
-   IntegraÃ§Ã£o com dashboards analÃ­ticos.

------------------------------------------------------------------------

## ğŸ§¾ LicenÃ§a

Este projeto Ã© de uso interno e educativo.\
Desenvolvido com foco em automaÃ§Ã£o e integraÃ§Ã£o de dados
administrativos e profissionais.


